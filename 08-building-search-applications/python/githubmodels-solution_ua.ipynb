{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a303c609",
   "metadata": {},
   "source": [
    "Щоб запустити наступні записники, додайте персональний токен GitHub у `.env` як `GITHUB_TOKEN`. Токен потрібен для використання GitHub Models через Azure AI Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Покрокова інструкція для практичної роботи №5\n",
    "\n",
    "1. Перевірте `.env`, щоб містив оновлений `GITHUB_TOKEN` з доступом `models:read`, та перезапустіть ядро перед запуском ноутбука.\n",
    "2. Запустіть комірку з `pip install`, щоб переконатися, що інстальовані `azure-ai-inference` та `python-dotenv`.\n",
    "3. По черзі виконуйте блоки, обов'язково зберігайте локальну копію `embedding_index_githubmodels.json` для повторних запусків.\n",
    "4. Зафіксуйте власні запити і результати у звіті: вони будуть потрібні для індивідуального завдання та захисту.\n",
    "5. Порівняйте поведінку цього ноутбука з AIMLAPI-варіантом, як вимагають методичні рекомендації.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3402d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-inference in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (1.0.0b9)\n",
      "Requirement already satisfied: python-dotenv in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (1.2.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from azure-ai-inference) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from azure-ai-inference) (1.36.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from azure-ai-inference) (4.15.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/serhiizabolotnii/Projects/DSP_LR_Python/.venv_lab/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-inference python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaddc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.inference import EmbeddingsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\", \"\")\n",
    "assert token, \"ERROR: GITHUB_TOKEN is missing. Будь ласка, додайте його у .env або середовище.\"\n",
    "\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "embed_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.3\n",
    "DATASET_PATH = Path(\"../embedding_index_3m.json\")\n",
    "CACHE_PATH = Path(\"../embedding_index_githubmodels.json\")\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "embed_client = EmbeddingsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf1602",
   "metadata": {},
   "source": [
    "Далі завантажимо індекс відео у `pandas` DataFrame та переконаємось, що дані готові до побудови векторів. Після виконання цієї комірки перегляньте розмірність набору даних, щоб описати його у звіті.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36539db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: Path) -> pd.DataFrame:\n",
    "    df = pd.read_json(source).fillna(\"\")\n",
    "    return df.drop(columns=[\"ada_v2\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75254164",
   "metadata": {},
   "source": [
    "Наступна функція створює або завантажує ембедінги за допомогою GitHub Models. Перший запуск може тривати кілька хвилин, адже потрібно обробити всі записи.\n",
    "\n",
    "> **Нотатка для звіту:** зафіксуйте час побудови індексу та порівняйте його з AIMLAPI-рішенням. Якщо використовується кеш, опишіть, як він пришвидшує повторні запуски.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940f3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load_github_index(df: pd.DataFrame, cache_path: Path | None = None, batch_size: int = 32) -> pd.DataFrame:\n",
    "    if cache_path and cache_path.exists():\n",
    "        cached_df = pd.read_json(cache_path).fillna(\"\")\n",
    "        if \"github_embedding\" in cached_df.columns:\n",
    "            print(f\"Завантажено вбудовування з кешу: {cache_path}\")\n",
    "            return cached_df\n",
    "        else:\n",
    "            print(\"Кеш знайдено, але без стовпчика 'github_embedding'. Створюємо індекс заново.\")\n",
    "\n",
    "    summaries = df[\"summary\"].tolist()\n",
    "    embeddings: list[list[float]] = []\n",
    "\n",
    "    total = len(summaries)\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = summaries[start:start + batch_size]\n",
    "        response = embed_client.embed(\n",
    "            input=batch,\n",
    "            model=embed_model_name,\n",
    "        )\n",
    "        embeddings.extend([item.embedding for item in response.data])\n",
    "        done = min(start + batch_size, total)\n",
    "        print(f\"Оброблено {done} / {total} записів\", end=\"\\r\")\n",
    "\n",
    "    print()\n",
    "    enriched_df = df.copy()\n",
    "    enriched_df[\"github_embedding\"] = embeddings\n",
    "\n",
    "    if cache_path:\n",
    "        enriched_df.to_json(cache_path, orient=\"records\")\n",
    "        print(f\"Індекс збережено до {cache_path}\")\n",
    "\n",
    "    return enriched_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81c34ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оброблено 1409 / 1409 записів\n",
      "Індекс збережено до ../embedding_index_githubmodels.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>videoId</th>\n",
       "      <th>start</th>\n",
       "      <th>seconds</th>\n",
       "      <th>summary</th>\n",
       "      <th>github_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Join Seth Juarez as he discusses ethical conce...</td>\n",
       "      <td>[0.05830316, 0.0032841517, 0.017757142, 0.0241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:03:07</td>\n",
       "      <td>187</td>\n",
       "      <td>In this video, the speaker discusses the chall...</td>\n",
       "      <td>[0.034540925, 0.010548099, 0.04061352, 0.00216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:06:13</td>\n",
       "      <td>373</td>\n",
       "      <td>The video discusses the limitations of general...</td>\n",
       "      <td>[0.027302632, 0.026398426, 0.040799573, -0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:09:21</td>\n",
       "      <td>561</td>\n",
       "      <td>The video discusses the importance of consider...</td>\n",
       "      <td>[0.045100074, -0.00481684, 0.030940464, 0.0169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:12:24</td>\n",
       "      <td>744</td>\n",
       "      <td>The video discusses the importance of understa...</td>\n",
       "      <td>[0.017057244, 0.029829111, 0.03688313, 0.02129...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 speaker  \\\n",
       "0  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "1  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "2  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "3  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "4  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "\n",
       "                                               title      videoId     start  \\\n",
       "0  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:00:00   \n",
       "1  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:03:07   \n",
       "2  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:06:13   \n",
       "3  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:09:21   \n",
       "4  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:12:24   \n",
       "\n",
       "   seconds                                            summary  \\\n",
       "0        0  Join Seth Juarez as he discusses ethical conce...   \n",
       "1      187  In this video, the speaker discusses the chall...   \n",
       "2      373  The video discusses the limitations of general...   \n",
       "3      561  The video discusses the importance of consider...   \n",
       "4      744  The video discusses the importance of understa...   \n",
       "\n",
       "                                    github_embedding  \n",
       "0  [0.05830316, 0.0032841517, 0.017757142, 0.0241...  \n",
       "1  [0.034540925, 0.010548099, 0.04061352, 0.00216...  \n",
       "2  [0.027302632, 0.026398426, 0.040799573, -0.000...  \n",
       "3  [0.045100074, -0.00481684, 0.030940464, 0.0169...  \n",
       "4  [0.017057244, 0.029829111, 0.03688313, 0.02129...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df = load_dataset(DATASET_PATH)\n",
    "videos_df = build_or_load_github_index(videos_df, CACHE_PATH, batch_size=BATCH_SIZE)\n",
    "videos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6e6ce",
   "metadata": {},
   "source": [
    "Додамо функції для обчислення косинусної подібності та отримання ембедінга запиту. Ці блоки можна винести у власні модулі, якщо ви будуєте продакшн-рішення. Додайте короткий опис алгебри косинусної подібності у звіт.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e11b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec_a, vec_b) -> float:\n",
    "    a = np.array(vec_a)\n",
    "    b = np.array(vec_b)\n",
    "    denom = np.linalg.norm(a) * np.linalg.norm(b)\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "def get_query_embedding(query: str) -> list[float]:\n",
    "    response = embed_client.embed(\n",
    "        input=[query],\n",
    "        model=embed_model_name,\n",
    "    )\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed6ce0",
   "metadata": {},
   "source": [
    "Функція `get_videos` поверне найбільш релевантні відео для запиту. Налаштуйте параметр `rows`, щоб отримати різну кількість результатів, та проаналізуйте відмінності у відборі.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5cb6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(query: str, video_vectors: pd.DataFrame, rows: int = 5, threshold: float | None = SIMILARITY_THRESHOLD) -> pd.DataFrame:\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    scored = video_vectors.copy()\n",
    "    scored[\"similarity\"] = scored[\"github_embedding\"].apply(lambda emb: cosine_similarity(query_embedding, emb))\n",
    "    scored = scored.sort_values(\"similarity\", ascending=False)\n",
    "    if threshold is not None:\n",
    "        scored = scored[scored[\"similarity\"] >= threshold]\n",
    "    return scored.head(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b39e9",
   "metadata": {},
   "source": [
    "Допоміжна функція красиво виводить результати пошуку. Ви можете замінити її на власний формат (наприклад, таблицю або JSON), якщо того потребує ваше індивідуальне завдання.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b87a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    if videos.empty:\n",
    "        print(f\"\\nНе знайдено результатів для запиту: '{query}'. Спробуйте змінити запит або зменшити поріг схожості.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nВідео, схожі на '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], int(row[\"seconds\"]))\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Резюме: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Схожість: {row['similarity']:.3f}\")\n",
    "        print(f\"   Доповідачі: {row['speaker']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a2911",
   "metadata": {},
   "source": [
    "Спробуйте пошук за прикладом, а потім підставте власні запити. Для звіту додайте принаймні два запити з різними темами та поясніть, наскільки результати задовольняють інформаційну потребу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e193f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Відео, схожі на 'Що таке ONNX?':\n",
      " - AI Show | Scikit-Learn with Andreas Müller\n",
      "   Резюме: ONNX is a serialization format developed by Microsoft, Nvidia, and other companies that allows for...\n",
      "   YouTube: https://youtu.be/ZEq0ivR_pzg?t=1109\n",
      "   Схожість: 0.817\n",
      "   Доповідачі: Andreas Müller, Seth Juarez\n",
      " - Faster and Lighter Model Inference with ONNX Runtime from Cloud to Client\n",
      "   Резюме: ONNX Runtime, a high-performance inference engine, is being used by a variety of popular frameworks...\n",
      "   YouTube: https://youtu.be/WDww8ce12Mc?t=184\n",
      "   Схожість: 0.745\n",
      "   Доповідачі: Emma\n",
      " - ONNX Runtime speeds up Image Embedding model in Bing Semantic Precise Image Search\n",
      "   Резюме: In this episode of the AI Show, Vinitra Swamy from the ONNX engineering team at...\n",
      "   YouTube: https://youtu.be/pmb6cjngbcA?t=0\n",
      "   Схожість: 0.714\n",
      "   Доповідачі: Vinitra Swamy\n",
      " - ONNX Runtime speeds up Image Embedding model in Bing Semantic Precise Image Search\n",
      "   Резюме: The video discusses the ONNX Runtime, an open-source scoring engine for ONNX models. It is...\n",
      "   YouTube: https://youtu.be/pmb6cjngbcA?t=363\n",
      "   Схожість: 0.704\n",
      "   Доповідачі: Vinitra Swamy\n",
      " - Faster and Lighter Model Inference with ONNX Runtime from Cloud to Client\n",
      "   Резюме: ONNX Runtime, integrated into various platforms including Azure ML and Oracle, is used by millions...\n",
      "   YouTube: https://youtu.be/WDww8ce12Mc?t=369\n",
      "   Схожість: 0.698\n",
      "   Доповідачі: Emma\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"Що таке ONNX?\"\n",
    "sample_videos = get_videos(sample_query, videos_df, rows=5)\n",
    "display_results(sample_videos, sample_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Поради щодо індивідуального завдання\n",
    "\n",
    "- Збережіть ембедінги у кеш-файл і використовуйте його для експериментів з різними запитами, щоб не перевищувати ліміти GitHub Models.\n",
    "- Для статистичних підзавдань (графіки, частоти, кластери) можна використовувати `pandas`, `matplotlib` або `scikit-learn` у додаткових комірках цього ноутбука.\n",
    "- Документуйте параметри запитів, фільтри та метрики, які використовуєте, щоб легко захистити роботу.\n",
    "- Порівняйте результати з AIMLAPI-ноутбуком та опишіть відмінності у якості, швидкості та вартості.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
