{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб запустити наступні записники, якщо ви ще цього не зробили, вам потрібно створити обліковий запис на [AIMLAPI](https://aimlapi.com/) та отримати **API_KEY** і встановити ключ у файлі .env як `AIMLAPI_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.66.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/vscode/.local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vscode/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vscode/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ AIMLAPI_KEY не знайдено у файлі .env\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"AIMLAPI_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: AIMLAPI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далі ми завантажимо індекс вбудовувань у Pandas DataFrame. Індекс вбудовувань зберігається в JSON-файлі під назвою `embedding_index_3m.json`. Індекс вбудовувань містить вбудовування для кожного транскрипту YouTube до кінця жовтня 2023 року."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Завантаження індексу відеосесій\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далі ми створимо функцію під назвою `get_videos`, яка шукатиме в індексі вбудовувань за запитом. Функція поверне 5 найрелевантніших відео, які найбільш схожі на запит. Функція працює наступним чином:\n",
    "\n",
    "1. Спочатку створюється копія індексу вбудовувань.\n",
    "2. Далі обчислюється вбудовування для запиту за допомогою API вбудовування OpenAI.\n",
    "3. Потім в індексі вбудовувань створюється новий стовпчик під назвою `similarity`. Стовпчик `similarity` містить косинусну подібність між вбудовуванням запиту та вбудовуванням для кожного сегмента відео.\n",
    "4. Далі індекс вбудовувань фільтрується за стовпчиком `similarity`. Індекс вбудовувань фільтрується, щоб включати тільки ті відео, які мають косинусну подібність більшу або рівну 0.75.\n",
    "5. Нарешті, індекс вбудовувань сортується за стовпчиком `similarity`, і повертаються 5 найкращих відео."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # створення копії набору даних\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # отримання вбудовувань для запиту за допомогою прямого виклику API\n",
    "    response = requests.post(\n",
    "        \"https://api.aimlapi.com/v1/embeddings\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"input\": query,\n",
    "            \"encoding_format\": \"float\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data = response.json()\n",
    "    query_embeddings = data[\"data\"][0][\"embedding\"]\n",
    "    \n",
    "    # створення нового стовпчика з обчисленою подібністю для кожного рядка\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # повернення верхніх рядків\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ця функція дуже проста, вона просто виводить результати пошукового запиту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"конвертація часу з формату 00:00:00 в секунди\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nВідео, схожі на '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Резюме: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Схожість: {row['similarity']}\")\n",
    "        print(f\"   Доповідачі: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Спочатку індекс вбудовувань завантажується в DataFrame Pandas.\n",
    "2. Далі користувачу пропонується ввести запит.\n",
    "3. Потім викликається функція `get_videos` для пошуку в індексі вбудовувань за запитом.\n",
    "4. Нарешті, викликається функція `display_results` для відображення результатів користувачу.\n",
    "5. Потім користувачу пропонується ввести інший запит. Цей процес триває, доки користувач не введе `exit`.\n",
    "\n",
    "![](../images/notebook-search.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Вам буде запропоновано ввести запит. Введіть запит і натисніть Enter. Застосунок поверне список відео, які відповідають запиту. Застосунок також поверне посилання на місце у відео, де знаходиться відповідь на запитання.\n",
    "\n",
    "Ось кілька запитів, які можна спробувати:\n",
    "\n",
    "- Що таке Azure Machine Learning?\n",
    "- Як працюють згорткові нейронні мережі?\n",
    "- Що таке нейронна мережа?\n",
    "- Чи можу я використовувати Jupyter Notebooks з Azure Machine Learning?\n",
    "- Що таке ONNX?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pd_vectors = load_dataset(\u001b[43mDATASET_NAME\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# отримання запиту користувача з вводу\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'DATASET_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# отримання запиту користувача з вводу\n",
    "while True:\n",
    "    query = input(\"Введіть запит: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Індивідуальне завдання\n",
    "> Виконати пошук фрагментів, що містять \"Computer Vision\". Знайти найрелевантніший фрагмент за косинусною подібністю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Критична помилка: AIMLAPI_KEY не знайдено.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m load_dotenv()\n\u001b[32m      9\u001b[39m API_KEY_SECURE = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mAIMLAPI_KEY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m API_KEY_SECURE, \u001b[33m\"\u001b[39m\u001b[33mКритична помилка: AIMLAPI_KEY не знайдено.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Константи варіанту\u001b[39;00m\n\u001b[32m     13\u001b[39m TARGET_TOPIC = \u001b[33m\"\u001b[39m\u001b[33mComputer Vision\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Критична помилка: AIMLAPI_KEY не знайдено."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Завантажуємо ключі\n",
    "load_dotenv()\n",
    "API_KEY_SECURE = os.getenv(\"AIMLAPI_KEY\", \"\")\n",
    "assert API_KEY_SECURE, \"Критична помилка: AIMLAPI_KEY не знайдено.\"\n",
    "\n",
    "# Константи варіанту\n",
    "TARGET_TOPIC = \"Computer Vision\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "FILE_PATH = \"embedding_index_3m.json\"\n",
    "\n",
    "def calculate_cosine(vec1, vec2):\n",
    "    \"\"\"Обчислення косинусної схожості між двома векторами.\"\"\"\n",
    "    v1, v2 = np.array(vec1), np.array(vec2)\n",
    "    norm_product = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return np.dot(v1, v2) / norm_product if norm_product > 0 else 0.0\n",
    "\n",
    "def fetch_query_vector(text_input):\n",
    "    \"\"\"Отримання вбудовування через API з обробкою помилок.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY_SECURE}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": EMBEDDING_MODEL,\n",
    "        \"input\": text_input\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        req = requests.post(\"https://api.aimlapi.com/v1/embeddings\", \n",
    "                            headers=headers, json=payload, timeout=30)\n",
    "        res_json = req.json()\n",
    "        \n",
    "        # Перевірка наявності даних у відповіді\n",
    "        if \"data\" in res_json:\n",
    "            return np.array(res_json[\"data\"][0][\"embedding\"])\n",
    "        else:\n",
    "            print(f\"Помилка API: {res_json}\")\n",
    "            return None\n",
    "    except Exception as err:\n",
    "        print(f\"Помилка з'єднання: {err}\")\n",
    "        return None\n",
    "\n",
    "def run_vision_search(df_source):\n",
    "    \"\"\"Пошук та аналіз фрагментів Computer Vision.\"\"\"\n",
    "    # 1. Фільтрація за ключовим словом у резюме\n",
    "    matches = df_source[df_source[\"summary\"].str.contains(TARGET_TOPIC, case=False, na=False)].copy()\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(f\"Фрагментів за темою '{TARGET_TOPIC}' не виявлено.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Знайдено {len(matches)} релевантних фрагментів. Починаємо розрахунок подібності...\")\n",
    "\n",
    "    # 2. Отримання вектора запиту\n",
    "    target_vector = fetch_query_vector(TARGET_TOPIC)\n",
    "    if target_vector is None: return\n",
    "\n",
    "    # 3. Обчислення схожості для кожного знайденого рядка\n",
    "    matches[\"similarity_score\"] = matches[\"ada_v2\"].apply(lambda x: calculate_cosine(target_vector, x))\n",
    "\n",
    "    # 4. Визначення абсолютного лідера\n",
    "    top_result = matches.sort_values(\"similarity_score\", ascending=False).iloc[0]\n",
    "\n",
    "    # 5. Красивий вивід результатів\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"РЕЗУЛЬТАТ ПОШУКУ ДЛЯ: '{TARGET_TOPIC}'\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Відео: {top_result['title']}\")\n",
    "    print(f\"Спікер: {top_result['speaker']}\")\n",
    "    print(f\"Схожість: {top_result['similarity_score']:.4f}\")\n",
    "    print(f\"Посилання: https://youtu.be/{top_result['videoId']}?t={int(top_result['seconds'])}\")\n",
    "    print(f\"Короткий зміст: {top_result['summary'][:200]}...\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Завантаження даних\n",
    "    data_frame = pd.read_json(FILE_PATH)\n",
    "    # Очищуємо від зайвого тексту для економії пам'яті\n",
    "    if \"text\" in data_frame.columns:\n",
    "        data_frame = data_frame.drop(columns=[\"text\"])\n",
    "    \n",
    "    run_vision_search(data_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
